{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69d660bb-ee56-4ce8-a680-261871fcdcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import wordnet as wn\n",
    "from gensim.models.poincare import PoincareModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from gensim.models.poincare import PoincareModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from gensim.models.poincare import PoincareModel\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce8a7324-473f-4219-8fed-df20eff6c43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yoel1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f337aa-4982-4ff0-8c96-67d6b3c0ab4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building transitive closure for the Mammal subtree...\n",
      "Total transitive hypernym pairs (mammal subtree): 7051\n",
      "Train relations: 5640\n",
      "Test relations : 1411\n",
      "========================================================\n",
      "RUNNING: dim=5, flip=0.0\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=5, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-10.186642759436284, kappa=-3.767014227323029e-05\n",
      "========================================================\n",
      "RUNNING: dim=5, flip=0.1\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=5, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-0.14581784152425822, kappa=-0.8643151311726412\n",
      "========================================================\n",
      "RUNNING: dim=5, flip=0.3\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=5, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-0.3242996127880126, kappa=-0.7230335798173502\n",
      "========================================================\n",
      "RUNNING: dim=10, flip=0.0\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=10, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-5.224568299684796, kappa=-0.005382683164429406\n",
      "========================================================\n",
      "RUNNING: dim=10, flip=0.1\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=10, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-0.13917028857484948, kappa=-0.8700798511842979\n",
      "========================================================\n",
      "RUNNING: dim=10, flip=0.3\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=10, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-0.36769901204454897, kappa=-0.6923255319780703\n",
      "========================================================\n",
      "RUNNING: dim=20, flip=0.0\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=20, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-6.213098236069144, kappa=-0.00200302200553819\n",
      "========================================================\n",
      "RUNNING: dim=20, flip=0.1\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=20, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-0.1979568213935338, kappa=-0.8204052763296329\n",
      "========================================================\n",
      "RUNNING: dim=20, flip=0.3\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=20, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-0.3295499122695804, kappa=-0.7192473850137905\n",
      "========================================================\n",
      "RUNNING: dim=50, flip=0.0\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=50, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-0.11822995331950845, kappa=-0.8884917175019538\n",
      "========================================================\n",
      "RUNNING: dim=50, flip=0.1\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=50, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-0.14837550951046424, kappa=-0.8621073246532356\n",
      "========================================================\n",
      "RUNNING: dim=50, flip=0.3\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=50, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-0.3661848759924767, kappa=-0.6933746010420285\n",
      "========================================================\n",
      "RUNNING: dim=100, flip=0.0\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=100, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-34.72396262188093, kappa=-8.309495242300422e-16\n",
      "========================================================\n",
      "RUNNING: dim=100, flip=0.1\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=100, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-0.1478388119734759, kappa=-0.8625701397157394\n",
      "========================================================\n",
      "RUNNING: dim=100, flip=0.3\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=100, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-0.37135891570822344, kappa=-0.68979631838938\n",
      "========================================================\n",
      "RUNNING: dim=200, flip=0.0\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=200, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-0.13369202119748033, kappa=-0.8748594612862307\n",
      "========================================================\n",
      "RUNNING: dim=200, flip=0.1\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=200, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-0.17574612544271886, kappa=-0.838830914134034\n",
      "========================================================\n",
      "RUNNING: dim=200, flip=0.3\n",
      "========================================================\n",
      "[INFO] Training Poincaré (dim=200, epochs=100) ...\n",
      "[INFO] kappa reparam => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] Final alpha=-0.3627272499025848, kappa=-0.6957761806421922\n",
      "\n",
      "All experiment results saved to: Y:\\Data Science Readings\\Geometry of Information\\Milestone 3\\Milestone3-Mammals\\MammalsM3Exp.xlsx\n",
      "\n",
      "Final DataFrame of all runs:\n",
      "\n",
      "    embedding_dim  flip_probability  subset_size  test_size  epochs  \\\n",
      "0               5               0.0        10000        0.2     100   \n",
      "1               5               0.1        10000        0.2     100   \n",
      "2               5               0.3        10000        0.2     100   \n",
      "3              10               0.0        10000        0.2     100   \n",
      "4              10               0.1        10000        0.2     100   \n",
      "5              10               0.3        10000        0.2     100   \n",
      "6              20               0.0        10000        0.2     100   \n",
      "7              20               0.1        10000        0.2     100   \n",
      "8              20               0.3        10000        0.2     100   \n",
      "9              50               0.0        10000        0.2     100   \n",
      "10             50               0.1        10000        0.2     100   \n",
      "11             50               0.3        10000        0.2     100   \n",
      "12            100               0.0        10000        0.2     100   \n",
      "13            100               0.1        10000        0.2     100   \n",
      "14            100               0.3        10000        0.2     100   \n",
      "15            200               0.0        10000        0.2     100   \n",
      "16            200               0.1        10000        0.2     100   \n",
      "17            200               0.3        10000        0.2     100   \n",
      "\n",
      "    n_negatives_strict  reconstruction_mean_rank_strict  \\\n",
      "0                   50                         4.776064   \n",
      "1                   50                         7.289716   \n",
      "2                   50                         8.264362   \n",
      "3                   50                         3.633865   \n",
      "4                   50                         6.108156   \n",
      "5                   50                         7.738121   \n",
      "6                   50                         3.146986   \n",
      "7                   50                         6.584752   \n",
      "8                   50                         8.591489   \n",
      "9                   50                         4.139184   \n",
      "10                  50                         6.389894   \n",
      "11                  50                         8.486525   \n",
      "12                  50                         3.056915   \n",
      "13                  50                         5.715780   \n",
      "14                  50                         7.993972   \n",
      "15                  50                         3.512411   \n",
      "16                  50                         6.235106   \n",
      "17                  50                         7.972163   \n",
      "\n",
      "    reconstruction_map_strict  lp_mean_rank    lp_map  lp_precision_10  \\\n",
      "0                    0.415921      5.340925  0.373471         0.883274   \n",
      "1                    0.341282      6.696797  0.341546         0.807117   \n",
      "2                    0.350994      8.298932  0.319444         0.702491   \n",
      "3                    0.480068      3.938790  0.440014         0.965836   \n",
      "4                    0.436125      5.790747  0.410107         0.844128   \n",
      "5                    0.381189      6.871174  0.369726         0.781495   \n",
      "6                    0.520711      3.532384  0.478039         0.979359   \n",
      "7                    0.425691      5.945907  0.408851         0.827758   \n",
      "8                    0.375237      8.130961  0.349389         0.730249   \n",
      "9                    0.706904      4.178648  0.671538         0.933096   \n",
      "10                   0.444178      5.891815  0.419339         0.823488   \n",
      "11                   0.374809      8.145907  0.349630         0.773665   \n",
      "12                   0.534114      3.312456  0.508524         0.985765   \n",
      "13                   0.500890      5.229181  0.475994         0.846263   \n",
      "14                   0.373411      7.375089  0.349997         0.767972   \n",
      "15                   0.676128      3.728114  0.644656         0.946619   \n",
      "16                   0.471732      6.044840  0.443036         0.832028   \n",
      "17                   0.375573      7.009253  0.373276         0.765836   \n",
      "\n",
      "    lp_recall_10  \n",
      "0       0.883274  \n",
      "1       0.807117  \n",
      "2       0.702491  \n",
      "3       0.965836  \n",
      "4       0.844128  \n",
      "5       0.781495  \n",
      "6       0.979359  \n",
      "7       0.827758  \n",
      "8       0.730249  \n",
      "9       0.933096  \n",
      "10      0.823488  \n",
      "11      0.773665  \n",
      "12      0.985765  \n",
      "13      0.846263  \n",
      "14      0.767972  \n",
      "15      0.946619  \n",
      "16      0.832028  \n",
      "17      0.765836  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "import autograd\n",
    "from autograd import grad\n",
    "import autograd.numpy as anp  \n",
    "from types import MethodType\n",
    "\n",
    "from gensim.models.poincare import (\n",
    "    PoincareKeyedVectors,\n",
    "    PoincareModel,\n",
    "    PoincareBatch\n",
    ")\n",
    "\n",
    "\n",
    "def no_op_compute_all(self):\n",
    "\n",
    "    self.loss = 0.0\n",
    "\n",
    "\n",
    "PoincareBatch.compute_all = no_op_compute_all\n",
    "\n",
    "\n",
    "\n",
    "def anp_safe_norm(x, axis=None, eps=1e-9):\n",
    "\n",
    "    return anp.sqrt(anp.sum(x * x, axis=axis) + eps)\n",
    "\n",
    "def anp_safe_arccosh(x, eps=1e-9):\n",
    "\n",
    "    clipped_x = anp.clip(x, 1.0 + eps, 1e15)\n",
    "    inside = clipped_x * clipped_x - 1.0\n",
    "    return anp.log(clipped_x + anp.sqrt(inside + eps))\n",
    "\n",
    "\n",
    "def custom_loss_with_alpha(matrix, alpha, regularization_coeff=1.0):\n",
    "\n",
    "    kappa = -anp.exp(alpha) \n",
    "    vector_u = matrix[0]\n",
    "    vectors_v = matrix[1:]  \n",
    "\n",
    "    \n",
    "    eucl_dists = anp_safe_norm(vector_u - vectors_v, axis=1)\n",
    "    norm_u = anp_safe_norm(vector_u)\n",
    "    norms_v = anp_safe_norm(vectors_v, axis=1)\n",
    "\n",
    "    denom_u = (1.0 + kappa * (norm_u**2))\n",
    "    denom_v = (1.0 + kappa * (norms_v**2))\n",
    "    denom = denom_u * denom_v\n",
    "    denom = anp.clip(denom, 1e-9, 1e15)\n",
    "\n",
    "    gamma = 1.0 + 2.0 * (eucl_dists**2) / denom\n",
    "    gamma = anp.clip(gamma, 1.0 + 1e-9, 1e15)\n",
    "\n",
    "    poincare_dists = anp_safe_arccosh(gamma)\n",
    "    exp_neg = anp.exp(-poincare_dists)\n",
    "\n",
    "    reg_term = regularization_coeff * anp.sum(vectors_v[0] * vectors_v[0])\n",
    "    return -anp.log(exp_neg[0] / anp.sum(exp_neg)) + reg_term\n",
    "\n",
    "_loss_grad_wrt_both = grad(custom_loss_with_alpha, argnum=[0, 1])\n",
    "\n",
    "\n",
    "\n",
    "def monkey_patch_train_on_batch_with_alpha(self, relations, check_gradients=False):\n",
    "\n",
    "    all_negatives = self._sample_negatives_batch(r[0] for r in relations)\n",
    "    batch = self._prepare_training_batch(relations, all_negatives, check_gradients)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    for (u, v), negs in zip(relations, all_negatives):\n",
    "        vec_u = self.kv.vectors[u]\n",
    "        vec_v = self.kv.vectors[v]\n",
    "        vec_negs = self.kv.vectors[negs]\n",
    "\n",
    "        sub_matrix = np.vstack((vec_u, vec_v, vec_negs))\n",
    "\n",
    "        grad_matrix, grad_alpha = _loss_grad_wrt_both(\n",
    "            sub_matrix, self.alpha, self.regularization_coeff\n",
    "        )\n",
    "\n",
    "        self.kv.vectors[u] -= self.alpha_emb * grad_matrix[0]\n",
    "        self.kv.vectors[v] -= self.alpha_emb * grad_matrix[1]\n",
    "        for i, neg_idx in enumerate(negs):\n",
    "            self.kv.vectors[neg_idx] -= self.alpha_emb * grad_matrix[2 + i]\n",
    "\n",
    "        self.kv.vectors[u] = self._clip_vectors(self.kv.vectors[u], self.epsilon)\n",
    "        self.kv.vectors[v] = self._clip_vectors(self.kv.vectors[v], self.epsilon)\n",
    "        self.kv.vectors[negs] = self._clip_vectors(self.kv.vectors[negs], self.epsilon)\n",
    "\n",
    "        self.alpha -= self.lr_alpha * grad_alpha\n",
    "\n",
    "        example_loss = float(custom_loss_with_alpha(sub_matrix, self.alpha, self.regularization_coeff))\n",
    "        total_loss += example_loss\n",
    "\n",
    "    batch.loss = total_loss / len(relations)\n",
    "    return batch\n",
    "\n",
    "\n",
    "\n",
    "def set_learnable_kappa_reparam(model, alpha_init=0.0, lr_alpha=1e-3, alpha_emb=0.1):\n",
    "    model.alpha = alpha_init\n",
    "    model.lr_alpha = lr_alpha\n",
    "    model.alpha_emb = alpha_emb\n",
    "    from types import MethodType\n",
    "    model._train_on_batch = MethodType(monkey_patch_train_on_batch_with_alpha, model)\n",
    "\n",
    "    print(f\"[INFO] kappa reparam => alpha_init={alpha_init}, lr_alpha={lr_alpha}, alpha_emb={alpha_emb}\")\n",
    "\n",
    "\n",
    "\n",
    "def curved_poincare_distance(u, v, alpha):\n",
    "\n",
    "    kappa = -np.exp(alpha)\n",
    "    eucl_dist = np.linalg.norm(u - v)\n",
    "    norm_u = np.linalg.norm(u)\n",
    "    norm_v = np.linalg.norm(v)\n",
    "\n",
    "    denom = (1.0 + kappa*norm_u**2) * (1.0 + kappa*norm_v**2)\n",
    "    if denom <= 1e-15:\n",
    "        denom = 1e-15\n",
    "    gamma = 1.0 + 2.0*(eucl_dist**2)/denom\n",
    "    if gamma < 1.0:\n",
    "        gamma = 1.0\n",
    "    return np.arccosh(gamma)\n",
    "\n",
    "def custom_vector_distance(self, u, v):\n",
    "    alpha = getattr(self, \"model_alpha\", 0.0)\n",
    "    return curved_poincare_distance(u, v, alpha)\n",
    "\n",
    "def custom_vector_distance_batch(self, u, all_v):\n",
    "    alpha = getattr(self, \"model_alpha\", 0.0)\n",
    "    # Vectorized\n",
    "    kappa = -np.exp(alpha)\n",
    "    euc_dists = np.linalg.norm(u - all_v, axis=1)\n",
    "    norm_u = np.linalg.norm(u)\n",
    "    norms_v = np.linalg.norm(all_v, axis=1)\n",
    "    denom = (1.0 + kappa*norm_u**2)*(1.0 + kappa*(norms_v**2))\n",
    "    denom[denom < 1e-15] = 1e-15\n",
    "    gamma = 1.0 + 2.0*(euc_dists**2)/denom\n",
    "    gamma[gamma < 1.0] = 1.0\n",
    "    return np.arccosh(gamma)\n",
    "\n",
    "PoincareKeyedVectors.vector_distance = custom_vector_distance\n",
    "PoincareKeyedVectors.vector_distance_batch = custom_vector_distance_batch\n",
    "\n",
    "def no_op_loss_fn(*args, **kwargs):\n",
    "    return 0.0\n",
    "\n",
    "PoincareModel._loss_fn = no_op_loss_fn \n",
    "\n",
    "\n",
    "def prepare_mammal_data(subset_size=10000, test_size=0.2, seed=42):\n",
    "\n",
    "    def extract_transitive_hypernyms_mammals():\n",
    "        mammal_synset = wn.synset('mammal.n.01')\n",
    "\n",
    "        mammal_synsets = set(mammal_synset.closure(lambda s: s.hyponyms()))\n",
    "        mammal_synsets.add(mammal_synset)\n",
    "\n",
    "        relations = []\n",
    "        for syn in mammal_synsets:\n",
    "            paths = syn.hypernym_paths() \n",
    "            for path in paths:\n",
    "                for ancestor in path:\n",
    "                    if ancestor in mammal_synsets and ancestor != syn:\n",
    "                        relations.append((syn.name(), ancestor.name()))\n",
    "        return relations\n",
    "\n",
    "    print(\"Building transitive closure for the Mammal subtree...\")\n",
    "    relations_list = extract_transitive_hypernyms_mammals()\n",
    "    print(f\"Total transitive hypernym pairs (mammal subtree): {len(relations_list)}\")\n",
    "\n",
    "    # Optional Subsample\n",
    "    if subset_size is not None and len(relations_list) > subset_size:\n",
    "        random.seed(seed)\n",
    "        relations_list = random.sample(relations_list, subset_size)\n",
    "        print(f\"Using a SUBSET of {subset_size} edges for faster testing.\")\n",
    "\n",
    "    # Train/Test Split\n",
    "    train_relations, test_relations = train_test_split(\n",
    "        relations_list, test_size=test_size, random_state=seed\n",
    "    )\n",
    "    print(f\"Train relations: {len(train_relations)}\")\n",
    "    print(f\"Test relations : {len(test_relations)}\")\n",
    "\n",
    "    combined_relations = train_relations + test_relations\n",
    "    return train_relations, test_relations, combined_relations\n",
    "\n",
    "\n",
    "def flip_edge_directions(relations, flip_probability=0.1, seed=42):\n",
    "    \"\"\"Flips each edge (u->v) to (v->u) with probability flip_probability.\"\"\"\n",
    "    random.seed(seed)\n",
    "    flipped = []\n",
    "    for (child, ancestor) in relations:\n",
    "        if random.random() < flip_probability:\n",
    "            flipped.append((ancestor, child))\n",
    "        else:\n",
    "            flipped.append((child, ancestor))\n",
    "    return flipped\n",
    "\n",
    "\n",
    "def train_and_evaluate_poincare(\n",
    "    train_relations,\n",
    "    test_relations,\n",
    "    combined_relations,\n",
    "    embedding_dim=5,\n",
    "    epochs=300,\n",
    "    n_negatives_strict=500,\n",
    "):\n",
    "\n",
    "    from gensim.models.poincare import PoincareModel\n",
    "\n",
    "    print(f\"[INFO] Training Poincaré (dim={embedding_dim}, epochs={epochs}) ...\")\n",
    "\n",
    "    model = PoincareModel(\n",
    "        train_data=train_relations,\n",
    "        size=embedding_dim,\n",
    "        negative=10,\n",
    "        burn_in=10\n",
    "    )\n",
    "    \n",
    "    set_learnable_kappa_reparam(model, alpha_init=0.0, lr_alpha=1e-3, alpha_emb=0.1)\n",
    "\n",
    "    \n",
    "    model.train(epochs=epochs)\n",
    "\n",
    "    \n",
    "    final_alpha = model.alpha\n",
    "    final_kappa = -np.exp(final_alpha)\n",
    "    print(f\"[INFO] Final alpha={final_alpha}, kappa={final_kappa}\")\n",
    "    model.kv.model_alpha = final_alpha  \n",
    "\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    u_to_all_neighbors = defaultdict(set)\n",
    "    for (c, a) in combined_relations:\n",
    "        u_to_all_neighbors[c].add(a)\n",
    "\n",
    "    vocab_nodes = set(model.kv.index_to_key)\n",
    "    vocab_list = list(vocab_nodes)\n",
    "    all_edges_set = set(combined_relations)\n",
    "\n",
    "    \n",
    "    recon_mr_strict = reconstruction_mean_rank_strict_sampled(\n",
    "        model, train_relations, u_to_all_neighbors, vocab_list, n_negatives_strict\n",
    "    )\n",
    "    recon_map_strict = reconstruction_map_strict_sampled(\n",
    "        model, train_relations, u_to_all_neighbors, vocab_list, n_negatives_strict\n",
    "    )\n",
    "\n",
    "    \n",
    "    lp_mr = link_prediction_mean_rank(model, test_relations, vocab_list, all_edges_set)\n",
    "    lp_map_ = link_prediction_map(model, test_relations, vocab_list, all_edges_set)\n",
    "    lp_p10 = precision_at_k(model, test_relations, vocab_list, all_edges_set, k=10)\n",
    "    lp_r10 = recall_at_k(model, test_relations, vocab_list, all_edges_set, k=10)\n",
    "\n",
    "    return {\n",
    "        \"reconstruction_mean_rank_strict\": recon_mr_strict,\n",
    "        \"reconstruction_map_strict\": recon_map_strict,\n",
    "        \"lp_mean_rank\": lp_mr,\n",
    "        \"lp_map\": lp_map_,\n",
    "        \"lp_precision_10\": lp_p10,\n",
    "        \"lp_recall_10\": lp_r10\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def reconstruction_mean_rank_strict_sampled(\n",
    "    model, edges, u_to_all_neighbors, vocab_list, n_negatives=500, seed=1234\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    ranks = []\n",
    "    for (u, v) in edges:\n",
    "        if (u not in model.kv) or (v not in model.kv):\n",
    "            continue\n",
    "        neighbors = u_to_all_neighbors[u]\n",
    "        neg_candidates = []\n",
    "        attempts = 0\n",
    "        while len(neg_candidates) < n_negatives and attempts < 10000:\n",
    "            candidate = rng.choice(vocab_list)\n",
    "            if candidate not in (u, v) and (candidate not in neighbors):\n",
    "                neg_candidates.append(candidate)\n",
    "            attempts += 1\n",
    "        candidates = neg_candidates + [v]\n",
    "        dists = [(c, model.kv.distance(u, c)) for c in candidates]\n",
    "        sorted_nodes = [x[0] for x in sorted(dists, key=lambda x: x[1])]\n",
    "        try:\n",
    "            rank = sorted_nodes.index(v) + 1\n",
    "            ranks.append(rank)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return float(np.mean(ranks)) if ranks else 0.0\n",
    "\n",
    "def reconstruction_map_strict_sampled(\n",
    "    model, edges, u_to_all_neighbors, vocab_list, n_negatives=500, seed=1234\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    reciprocal_ranks = []\n",
    "    for (u, v) in edges:\n",
    "        if (u not in model.kv) or (v not in model.kv):\n",
    "            continue\n",
    "        neighbors = u_to_all_neighbors[u]\n",
    "        neg_candidates = []\n",
    "        attempts = 0\n",
    "        while len(neg_candidates) < n_negatives and attempts < 10000:\n",
    "            candidate = rng.choice(vocab_list)\n",
    "            if candidate not in (u, v) and (candidate not in neighbors):\n",
    "                neg_candidates.append(candidate)\n",
    "            attempts += 1\n",
    "        candidates = neg_candidates + [v]\n",
    "        dists = [(c, model.kv.distance(u, c)) for c in candidates]\n",
    "        sorted_nodes = [x[0] for x in sorted(dists, key=lambda x: x[1])]\n",
    "        try:\n",
    "            r = sorted_nodes.index(v) + 1\n",
    "            reciprocal_ranks.append(1.0 / r)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return float(np.mean(reciprocal_ranks)) if reciprocal_ranks else 0.0\n",
    "\n",
    "\n",
    "def link_prediction_mean_rank(\n",
    "    model, edges, vocab_list, all_edges_set, num_negatives=50\n",
    "):\n",
    "    rng = np.random.default_rng(1234)\n",
    "    ranks = []\n",
    "    for (source, target) in edges:\n",
    "        if (source not in model.kv) or (target not in model.kv):\n",
    "            continue\n",
    "        neg_candidates = []\n",
    "        attempts = 0\n",
    "        while len(neg_candidates) < num_negatives and attempts < 10000:\n",
    "            candidate = rng.choice(vocab_list)\n",
    "            # Must not be the true target, nor an existing edge\n",
    "            if candidate != target and (source, candidate) not in all_edges_set:\n",
    "                neg_candidates.append(candidate)\n",
    "            attempts += 1\n",
    "        if not neg_candidates:\n",
    "            continue\n",
    "        candidates = neg_candidates + [target]\n",
    "        dists = [model.kv.distance(source, c) for c in candidates]\n",
    "        sorted_candidates = [c for _, c in sorted(zip(dists, candidates), key=lambda x: x[0])]\n",
    "        rank = sorted_candidates.index(target) + 1\n",
    "        ranks.append(rank)\n",
    "    return float(np.mean(ranks)) if ranks else 0.0\n",
    "\n",
    "def link_prediction_map(model, edges, vocab_list, all_edges_set, num_negatives=50):\n",
    "    rng = np.random.default_rng(1234)\n",
    "    reciprocal_ranks = []\n",
    "    for (source, target) in edges:\n",
    "        if (source not in model.kv) or (target not in model.kv):\n",
    "            continue\n",
    "        neg_candidates = []\n",
    "        attempts = 0\n",
    "        while len(neg_candidates) < num_negatives and attempts < 10000:\n",
    "            candidate = rng.choice(vocab_list)\n",
    "            if candidate != target and (source, candidate) not in all_edges_set:\n",
    "                neg_candidates.append(candidate)\n",
    "            attempts += 1\n",
    "        if not neg_candidates:\n",
    "            continue\n",
    "        candidates = neg_candidates + [target]\n",
    "        dists = [model.kv.distance(source, c) for c in candidates]\n",
    "        sorted_candidates = [c for _, c in sorted(zip(dists, candidates), key=lambda x: x[0])]\n",
    "        rank = sorted_candidates.index(target) + 1\n",
    "        reciprocal_ranks.append(1.0 / rank)\n",
    "    return float(np.mean(reciprocal_ranks)) if reciprocal_ranks else 0.0\n",
    "\n",
    "def precision_at_k(model, edges, vocab_list, all_edges_set, k=10, num_negatives=50):\n",
    "    rng = np.random.default_rng(1234)\n",
    "    hits = 0\n",
    "    count = 0\n",
    "    for (source, target) in edges:\n",
    "        if (source not in model.kv) or (target not in model.kv):\n",
    "            continue\n",
    "        neg_candidates = []\n",
    "        attempts = 0\n",
    "        while len(neg_candidates) < num_negatives and attempts < 10000:\n",
    "            candidate = rng.choice(vocab_list)\n",
    "            if candidate != target and (source, candidate) not in all_edges_set:\n",
    "                neg_candidates.append(candidate)\n",
    "            attempts += 1\n",
    "        if not neg_candidates:\n",
    "            continue\n",
    "        candidates = neg_candidates + [target]\n",
    "        dists = [model.kv.distance(source, c) for c in candidates]\n",
    "        sorted_candidates = [c for _, c in sorted(zip(dists, candidates), key=lambda x: x[0])]\n",
    "        top_k_nodes = sorted_candidates[:k]\n",
    "        if target in top_k_nodes:\n",
    "            hits += 1\n",
    "        count += 1\n",
    "    return hits / count if count else 0.0\n",
    "\n",
    "def recall_at_k(model, edges, vocab_list, all_edges_set, k=10, num_negatives=50):\n",
    "\n",
    "    return precision_at_k(model, edges, vocab_list, all_edges_set, k, num_negatives)\n",
    "\n",
    "\n",
    "\n",
    "def run_multiple_experiments(\n",
    "    address,                \n",
    "    dim_list,               \n",
    "    flip_list,              \n",
    "    subset_size=10000,\n",
    "    test_size=0.2,\n",
    "    epochs=300,\n",
    "    n_negatives_strict=500,\n",
    "    seed=42\n",
    "):\n",
    "   \n",
    "    train_rel_clean, test_rel, combined_rel = prepare_mammal_data(\n",
    "        subset_size=subset_size,\n",
    "        test_size=test_size,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "   \n",
    "    results_all = []\n",
    "    for dim in dim_list:\n",
    "        for flip_probability in flip_list:\n",
    "            print(\"========================================================\")\n",
    "            print(f\"RUNNING: dim={dim}, flip={flip_probability}\")\n",
    "            print(\"========================================================\")\n",
    "\n",
    "            \n",
    "            flipped_train = flip_edge_directions(train_rel_clean, flip_probability, seed=seed)\n",
    "\n",
    "            \n",
    "            stats = train_and_evaluate_poincare(\n",
    "                train_relations=flipped_train,\n",
    "                test_relations=test_rel,\n",
    "                combined_relations=combined_rel,\n",
    "                embedding_dim=dim,\n",
    "                epochs=epochs,\n",
    "                n_negatives_strict=n_negatives_strict\n",
    "            )\n",
    "\n",
    "            \n",
    "            row_info = {\n",
    "                \"embedding_dim\": dim,\n",
    "                \"flip_probability\": flip_probability,\n",
    "                \"subset_size\": subset_size,\n",
    "                \"test_size\": test_size,\n",
    "                \"epochs\": epochs,\n",
    "                \"n_negatives_strict\": n_negatives_strict\n",
    "            }\n",
    "            row_info.update(stats)\n",
    "            results_all.append(row_info)\n",
    "\n",
    "    df = pd.DataFrame(results_all)\n",
    "    df.to_excel(address, index=False)\n",
    "    print(f\"\\nAll experiment results saved to: {address}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dimension_list = [5, 10,20,50,100,200]\n",
    "    flip_probability_list = [0.0, 0.1, 0.3]\n",
    "    excel_path = \"Y:\\\\Data Science Readings\\\\Geometry of Information\\\\Milestone 3\\\\Milestone3-Mammals\\\\MammalsM3Exp.xlsx\"\n",
    "\n",
    "    final_df = run_multiple_experiments(\n",
    "        address=excel_path,\n",
    "        dim_list=dimension_list,\n",
    "        flip_list=flip_probability_list,\n",
    "        subset_size=10000,   # or smaller\n",
    "        test_size=0.2,\n",
    "        epochs=100,\n",
    "        n_negatives_strict=50,\n",
    "        seed=42\n",
    "    )\n",
    "    print(\"\\nFinal DataFrame of all runs:\\n\")\n",
    "    print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0207d828-9d3e-457a-907a-3bf863829a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
