{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67506017-6534-4efd-bff4-e7446fe0011d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total edges (before subsampling): 196\n",
      "Train relations: 156\n",
      "Test relations : 40\n",
      "========================================================\n",
      "RUNNING: dim=5, removal_prob=0.00\n",
      "========================================================\n",
      "Removed 0 edges from training set (prob=0.0).\n",
      "[INFO] Training Poincaré (dim=5, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-3.7438519710219467, => kappa=-0.023662779016233124\n",
      "========================================================\n",
      "RUNNING: dim=5, removal_prob=0.10\n",
      "========================================================\n",
      "Removed 19 edges from training set (prob=0.1).\n",
      "[INFO] Training Poincaré (dim=5, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.08607111079469706, => kappa=-0.9175289826851245\n",
      "========================================================\n",
      "RUNNING: dim=5, removal_prob=0.30\n",
      "========================================================\n",
      "Removed 54 edges from training set (prob=0.3).\n",
      "[INFO] Training Poincaré (dim=5, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.1241894524662365, => kappa=-0.8832124982455102\n",
      "========================================================\n",
      "RUNNING: dim=10, removal_prob=0.00\n",
      "========================================================\n",
      "Removed 0 edges from training set (prob=0.0).\n",
      "[INFO] Training Poincaré (dim=10, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.11978122848820714, => kappa=-0.8871144908679242\n",
      "========================================================\n",
      "RUNNING: dim=10, removal_prob=0.10\n",
      "========================================================\n",
      "Removed 19 edges from training set (prob=0.1).\n",
      "[INFO] Training Poincaré (dim=10, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.12927808217659406, => kappa=-0.8787295725343199\n",
      "========================================================\n",
      "RUNNING: dim=10, removal_prob=0.30\n",
      "========================================================\n",
      "Removed 54 edges from training set (prob=0.3).\n",
      "[INFO] Training Poincaré (dim=10, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.11594047394205867, => kappa=-0.8905282313548746\n",
      "========================================================\n",
      "RUNNING: dim=20, removal_prob=0.00\n",
      "========================================================\n",
      "Removed 0 edges from training set (prob=0.0).\n",
      "[INFO] Training Poincaré (dim=20, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.12276809153049215, => kappa=-0.884468754573815\n",
      "========================================================\n",
      "RUNNING: dim=20, removal_prob=0.10\n",
      "========================================================\n",
      "Removed 19 edges from training set (prob=0.1).\n",
      "[INFO] Training Poincaré (dim=20, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.13900901664975712, => kappa=-0.8702201819522848\n",
      "========================================================\n",
      "RUNNING: dim=20, removal_prob=0.30\n",
      "========================================================\n",
      "Removed 54 edges from training set (prob=0.3).\n",
      "[INFO] Training Poincaré (dim=20, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.14706075916309785, => kappa=-0.8632415259902128\n",
      "========================================================\n",
      "RUNNING: dim=50, removal_prob=0.00\n",
      "========================================================\n",
      "Removed 0 edges from training set (prob=0.0).\n",
      "[INFO] Training Poincaré (dim=50, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.13583858392051248, => kappa=-0.8729835346961002\n",
      "========================================================\n",
      "RUNNING: dim=50, removal_prob=0.10\n",
      "========================================================\n",
      "Removed 19 edges from training set (prob=0.1).\n",
      "[INFO] Training Poincaré (dim=50, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.08497882559004943, => kappa=-0.9185317335630234\n",
      "========================================================\n",
      "RUNNING: dim=50, removal_prob=0.30\n",
      "========================================================\n",
      "Removed 54 edges from training set (prob=0.3).\n",
      "[INFO] Training Poincaré (dim=50, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-4.8692728574888315, => kappa=-0.007678946947084947\n",
      "========================================================\n",
      "RUNNING: dim=100, removal_prob=0.00\n",
      "========================================================\n",
      "Removed 0 edges from training set (prob=0.0).\n",
      "[INFO] Training Poincaré (dim=100, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.09625962872862429, => kappa=-0.9082281833270155\n",
      "========================================================\n",
      "RUNNING: dim=100, removal_prob=0.10\n",
      "========================================================\n",
      "Removed 19 edges from training set (prob=0.1).\n",
      "[INFO] Training Poincaré (dim=100, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-5.396081226427337, => kappa=-0.0045343151260791225\n",
      "========================================================\n",
      "RUNNING: dim=100, removal_prob=0.30\n",
      "========================================================\n",
      "Removed 54 edges from training set (prob=0.3).\n",
      "[INFO] Training Poincaré (dim=100, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.1131148942977938, => kappa=-0.8930480480929784\n",
      "========================================================\n",
      "RUNNING: dim=200, removal_prob=0.00\n",
      "========================================================\n",
      "Removed 0 edges from training set (prob=0.0).\n",
      "[INFO] Training Poincaré (dim=200, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.10684801307039081, => kappa=-0.8986622475270277\n",
      "========================================================\n",
      "RUNNING: dim=200, removal_prob=0.10\n",
      "========================================================\n",
      "Removed 19 edges from training set (prob=0.1).\n",
      "[INFO] Training Poincaré (dim=200, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.12777150272397408, => kappa=-0.8800544462158448\n",
      "========================================================\n",
      "RUNNING: dim=200, removal_prob=0.30\n",
      "========================================================\n",
      "Removed 54 edges from training set (prob=0.3).\n",
      "[INFO] Training Poincaré (dim=200, epochs=100) ...\n",
      "[INFO] reparam kappa => alpha_init=0.0, lr_alpha=0.001, alpha_emb=0.1\n",
      "[INFO] final alpha=-0.1417877833215841, => kappa=-0.8678053997255307\n",
      "\n",
      "All experiment results saved to: Y:\\\\Data Science Readings\\\\Geometry of Information\\\\Milestone 3\\\\Milestone3-HebrewNet\\\\HebrewnetM3exp.xlsx\n",
      "\n",
      "Final DataFrame of all runs:\n",
      "\n",
      "    embedding_dim  edge_removal_probability  subset_size  test_size  epochs  \\\n",
      "0               5                       0.0        10000        0.2     100   \n",
      "1               5                       0.1        10000        0.2     100   \n",
      "2               5                       0.3        10000        0.2     100   \n",
      "3              10                       0.0        10000        0.2     100   \n",
      "4              10                       0.1        10000        0.2     100   \n",
      "5              10                       0.3        10000        0.2     100   \n",
      "6              20                       0.0        10000        0.2     100   \n",
      "7              20                       0.1        10000        0.2     100   \n",
      "8              20                       0.3        10000        0.2     100   \n",
      "9              50                       0.0        10000        0.2     100   \n",
      "10             50                       0.1        10000        0.2     100   \n",
      "11             50                       0.3        10000        0.2     100   \n",
      "12            100                       0.0        10000        0.2     100   \n",
      "13            100                       0.1        10000        0.2     100   \n",
      "14            100                       0.3        10000        0.2     100   \n",
      "15            200                       0.0        10000        0.2     100   \n",
      "16            200                       0.1        10000        0.2     100   \n",
      "17            200                       0.3        10000        0.2     100   \n",
      "\n",
      "    n_negatives_strict  reconstruction_mean_rank_strict  \\\n",
      "0                   50                         1.730769   \n",
      "1                   50                         4.627737   \n",
      "2                   50                         4.480392   \n",
      "3                   50                         3.891026   \n",
      "4                   50                         3.416058   \n",
      "5                   50                         4.039216   \n",
      "6                   50                         3.294872   \n",
      "7                   50                         4.000000   \n",
      "8                   50                         5.029412   \n",
      "9                   50                         3.621795   \n",
      "10                  50                         3.226277   \n",
      "11                  50                         1.950980   \n",
      "12                  50                         3.910256   \n",
      "13                  50                         1.693431   \n",
      "14                  50                         4.411765   \n",
      "15                  50                         2.487179   \n",
      "16                  50                         4.160584   \n",
      "17                  50                         3.362745   \n",
      "\n",
      "    reconstruction_map_strict  lp_mean_rank    lp_map  lp_precision_10  \\\n",
      "0                    0.758555        19.500  0.079803            0.125   \n",
      "1                    0.660431         8.375  0.260917            0.625   \n",
      "2                    0.655292         8.500  0.204653            0.625   \n",
      "3                    0.710002         9.250  0.282527            0.500   \n",
      "4                    0.716353        11.500  0.122055            0.375   \n",
      "5                    0.740394         8.500  0.156904            0.625   \n",
      "6                    0.761029         6.125  0.302431            1.000   \n",
      "7                    0.738521        12.750  0.191225            0.250   \n",
      "8                    0.717027        10.625  0.217225            0.375   \n",
      "9                    0.776346         7.125  0.201190            0.750   \n",
      "10                   0.790527         7.625  0.152232            0.875   \n",
      "11                   0.725735        12.500  0.208119            0.375   \n",
      "12                   0.754783         8.000  0.131358            0.750   \n",
      "13                   0.774209         9.500  0.134436            0.625   \n",
      "14                   0.676867         6.625  0.208395            0.875   \n",
      "15                   0.801083        11.375  0.134761            0.375   \n",
      "16                   0.677500        10.000  0.109749            0.625   \n",
      "17                   0.744589        12.125  0.132130            0.250   \n",
      "\n",
      "    lp_recall_10  \n",
      "0          0.125  \n",
      "1          0.625  \n",
      "2          0.625  \n",
      "3          0.500  \n",
      "4          0.375  \n",
      "5          0.625  \n",
      "6          1.000  \n",
      "7          0.250  \n",
      "8          0.375  \n",
      "9          0.750  \n",
      "10         0.875  \n",
      "11         0.375  \n",
      "12         0.750  \n",
      "13         0.625  \n",
      "14         0.875  \n",
      "15         0.375  \n",
      "16         0.625  \n",
      "17         0.250  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import autograd\n",
    "from autograd import grad\n",
    "import autograd.numpy as anp  \n",
    "from types import MethodType\n",
    "\n",
    "from gensim.models.poincare import (\n",
    "    PoincareKeyedVectors,\n",
    "    PoincareModel,\n",
    "    PoincareBatch\n",
    ")\n",
    "\n",
    "\n",
    "def no_op_compute_all(self):\n",
    "    self.loss = 0.0\n",
    "\n",
    "PoincareBatch.compute_all = no_op_compute_all\n",
    "\n",
    "\n",
    "\n",
    "def anp_safe_norm(x, axis=None, eps=1e-9):\n",
    "    return anp.sqrt(anp.sum(x * x, axis=axis) + eps)\n",
    "\n",
    "def anp_safe_arccosh(x, eps=1e-9):\n",
    "    clipped_x = anp.clip(x, 1.0 + eps, 1e15)\n",
    "    inside = clipped_x * clipped_x - 1.0\n",
    "    return anp.log(clipped_x + anp.sqrt(inside + eps))\n",
    "\n",
    "def custom_loss_with_alpha(matrix, alpha, regularization_coeff=1.0):\n",
    "\n",
    "    kappa = -anp.exp(alpha)\n",
    "    vector_u = matrix[0]\n",
    "    vectors_v = matrix[1:] \n",
    "    eucl_dist = anp_safe_norm(vector_u - vectors_v, axis=1)\n",
    "    norm_u = anp_safe_norm(vector_u)\n",
    "    norms_v = anp_safe_norm(vectors_v, axis=1)\n",
    "    denom_u = (1.0 + kappa * (norm_u**2))\n",
    "    denom_v = (1.0 + kappa * (norms_v**2))\n",
    "    denom = denom_u * denom_v\n",
    "    denom = anp.clip(denom, 1e-9, 1e15)\n",
    "\n",
    "    gamma = 1.0 + 2.0*(eucl_dist**2) / denom\n",
    "    gamma = anp.clip(gamma, 1.0 + 1e-9, 1e15)\n",
    "\n",
    "    poinc_dist = anp_safe_arccosh(gamma)\n",
    "    exp_neg = anp.exp(-poinc_dist)\n",
    "    reg_term = regularization_coeff * anp.sum(vectors_v[0] * vectors_v[0])\n",
    "\n",
    "    return -anp.log(exp_neg[0] / anp.sum(exp_neg)) + reg_term\n",
    "\n",
    "\n",
    "_loss_grad_wrt_both = grad(custom_loss_with_alpha, argnum=[0, 1])\n",
    "\n",
    "\n",
    "\n",
    "def monkey_patch_train_on_batch_with_alpha(self, relations, check_gradients=False):\n",
    "\n",
    "    all_negatives = self._sample_negatives_batch(r[0] for r in relations)\n",
    "    batch = self._prepare_training_batch(relations, all_negatives, check_gradients)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    for (u, v), negs in zip(relations, all_negatives):\n",
    "        vec_u = self.kv.vectors[u]\n",
    "        vec_v = self.kv.vectors[v]\n",
    "        vec_negs = self.kv.vectors[negs]\n",
    "        sub_matrix = np.vstack((vec_u, vec_v, vec_negs))\n",
    "        grad_matrix, grad_alpha = _loss_grad_wrt_both(\n",
    "            sub_matrix, self.alpha, self.regularization_coeff\n",
    "        )\n",
    "        self.kv.vectors[u] -= self.alpha_emb * grad_matrix[0]\n",
    "        self.kv.vectors[v] -= self.alpha_emb * grad_matrix[1]\n",
    "        for i, neg_idx in enumerate(negs):\n",
    "            self.kv.vectors[neg_idx] -= self.alpha_emb * grad_matrix[2 + i]\n",
    "        self.kv.vectors[u] = self._clip_vectors(self.kv.vectors[u], self.epsilon)\n",
    "        self.kv.vectors[v] = self._clip_vectors(self.kv.vectors[v], self.epsilon)\n",
    "        self.kv.vectors[negs] = self._clip_vectors(self.kv.vectors[negs], self.epsilon)\n",
    "        self.alpha -= self.lr_alpha * grad_alpha\n",
    "        example_loss = float(custom_loss_with_alpha(sub_matrix, self.alpha, self.regularization_coeff))\n",
    "        total_loss += example_loss\n",
    "\n",
    "    batch.loss = total_loss / len(relations)\n",
    "    return batch\n",
    "\n",
    "\n",
    "\n",
    "def set_learnable_kappa_reparam(model, alpha_init=0.0, lr_alpha=1e-3, alpha_emb=0.1):\n",
    "\n",
    "    model.alpha = alpha_init\n",
    "    model.lr_alpha = lr_alpha\n",
    "    model.alpha_emb = alpha_emb\n",
    "    model._train_on_batch = MethodType(monkey_patch_train_on_batch_with_alpha, model)\n",
    "\n",
    "    print(f\"[INFO] reparam kappa => alpha_init={alpha_init}, lr_alpha={lr_alpha}, alpha_emb={alpha_emb}\")\n",
    "\n",
    "\n",
    "def curved_poincare_distance(u, v, alpha):\n",
    "    kappa = -np.exp(alpha)  \n",
    "    eucl_dist = np.linalg.norm(u - v)\n",
    "    norm_u = np.linalg.norm(u)\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    denom = (1.0 + kappa*(norm_u**2))*(1.0 + kappa*(norm_v**2))\n",
    "    if denom <= 1e-15:\n",
    "        denom = 1e-15\n",
    "    gamma = 1.0 + 2.0*(eucl_dist**2)/denom\n",
    "    if gamma < 1.0:\n",
    "        gamma = 1.0\n",
    "    return np.arccosh(gamma)\n",
    "\n",
    "def custom_vector_distance(self, u, v):\n",
    "    alpha = getattr(self, \"model_alpha\", 0.0)  \n",
    "    return curved_poincare_distance(u, v, alpha)\n",
    "\n",
    "def custom_vector_distance_batch(self, u, all_v):\n",
    "    alpha = getattr(self, \"model_alpha\", 0.0)\n",
    "    kappa = -np.exp(alpha)\n",
    "    euc = np.linalg.norm(u - all_v, axis=1)\n",
    "    norm_u = np.linalg.norm(u)\n",
    "    norms_v = np.linalg.norm(all_v, axis=1)\n",
    "\n",
    "    denom = (1.0 + kappa*(norm_u**2))*(1.0 + kappa*(norms_v**2))\n",
    "    denom[denom < 1e-15] = 1e-15\n",
    "    gamma = 1.0 + 2.0*(euc**2)/denom\n",
    "    gamma[gamma < 1.0] = 1.0\n",
    "    return np.arccosh(gamma)\n",
    "\n",
    "PoincareKeyedVectors.vector_distance = custom_vector_distance\n",
    "PoincareKeyedVectors.vector_distance_batch = custom_vector_distance_batch\n",
    "\n",
    "def no_op_loss_fn(*args, **kwargs):\n",
    "    return 0.0\n",
    "\n",
    "PoincareModel._loss_fn = no_op_loss_fn\n",
    "\n",
    "\n",
    "\n",
    "def prepare_custom_data(\n",
    "    tsv_path,\n",
    "    hypernym_col=\"Hypernym\",\n",
    "    hyponym_col=\"Hyponym\",\n",
    "    subset_size=10000,\n",
    "    test_size=0.2,\n",
    "    seed=42\n",
    "):\n",
    "    df = pd.read_csv(tsv_path, sep=\"\\t\", header=0, names=[hypernym_col, hyponym_col])\n",
    "    relations_list = []\n",
    "    for i, row in df.iterrows():\n",
    "        hypernym = str(row[hypernym_col]).strip()\n",
    "        hyponym = str(row[hyponym_col]).strip()\n",
    "        if not hypernym or not hyponym or hypernym == \"nan\" or hyponym == \"nan\":\n",
    "            continue\n",
    "        relations_list.append((hyponym, hypernym))\n",
    "\n",
    "    print(f\"Total edges (before subsampling): {len(relations_list)}\")\n",
    "\n",
    "    if subset_size is not None and len(relations_list) > subset_size:\n",
    "        random.seed(seed)\n",
    "        relations_list = random.sample(relations_list, subset_size)\n",
    "        print(f\"Using a SUBSET of {subset_size} edges for faster testing.\")\n",
    "\n",
    "    train_relations, test_relations = train_test_split(\n",
    "        relations_list, test_size=test_size, random_state=seed\n",
    "    )\n",
    "    print(f\"Train relations: {len(train_relations)}\")\n",
    "    print(f\"Test relations : {len(test_relations)}\")\n",
    "\n",
    "    combined_relations = train_relations + test_relations\n",
    "    return train_relations, test_relations, combined_relations\n",
    "\n",
    "def remove_edges(relations, removal_probability=0.1, seed=42):\n",
    "    random.seed(seed)\n",
    "    kept = []\n",
    "    for (child, ancestor) in relations:\n",
    "        if random.random() > removal_probability:\n",
    "            kept.append((child, ancestor))\n",
    "    return kept\n",
    "\n",
    "def train_and_evaluate_poincare(\n",
    "    train_relations,\n",
    "    test_relations,\n",
    "    combined_relations,\n",
    "    embedding_dim=5,\n",
    "    epochs=300,\n",
    "    n_negatives_strict=500,\n",
    "):\n",
    "    from gensim.models.poincare import PoincareModel\n",
    "    print(f\"[INFO] Training Poincaré (dim={embedding_dim}, epochs={epochs}) ...\")\n",
    "\n",
    "    model = PoincareModel(\n",
    "        train_data=train_relations,\n",
    "        size=embedding_dim,\n",
    "        negative=10,\n",
    "        burn_in=10\n",
    "    )\n",
    "\n",
    "    set_learnable_kappa_reparam(model, alpha_init=0.0, lr_alpha=1e-3, alpha_emb=0.1)\n",
    "\n",
    "    model.train(epochs=epochs)\n",
    "\n",
    "    final_alpha = model.alpha\n",
    "    final_kappa = -np.exp(final_alpha)\n",
    "    print(f\"[INFO] final alpha={final_alpha}, => kappa={final_kappa}\")\n",
    "\n",
    "    model.kv.model_alpha = final_alpha\n",
    "\n",
    "    u_to_all_neighbors = defaultdict(set)\n",
    "    for (child, ancestor) in combined_relations:\n",
    "        u_to_all_neighbors[child].add(ancestor)\n",
    "\n",
    "    vocab_nodes = set(model.kv.index_to_key)\n",
    "    vocab_list = list(vocab_nodes)\n",
    "    all_edges_set = set(combined_relations)\n",
    "\n",
    "    def reconstruction_mean_rank_strict_sampled(model, edges, n_negatives=500, seed=1234):\n",
    "        rng = np.random.default_rng(seed)\n",
    "        ranks = []\n",
    "        for (u, v) in edges:\n",
    "            if (u not in model.kv) or (v not in model.kv):\n",
    "                continue\n",
    "            neighbors = u_to_all_neighbors[u]\n",
    "            neg_candidates = []\n",
    "            attempts = 0\n",
    "            while len(neg_candidates) < n_negatives and attempts < 10000:\n",
    "                candidate = rng.choice(vocab_list)\n",
    "                if candidate not in (u, v) and (candidate not in neighbors):\n",
    "                    neg_candidates.append(candidate)\n",
    "                attempts += 1\n",
    "            candidates = neg_candidates + [v]\n",
    "            dists = [(c, model.kv.distance(u, c)) for c in candidates]\n",
    "            sorted_nodes = [x[0] for x in sorted(dists, key=lambda x: x[1])]\n",
    "            try:\n",
    "                rank = sorted_nodes.index(v) + 1\n",
    "                ranks.append(rank)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        return float(np.mean(ranks)) if ranks else 0.0\n",
    "\n",
    "    def reconstruction_map_strict_sampled(model, edges, n_negatives=500, seed=1234):\n",
    "        rng = np.random.default_rng(seed)\n",
    "        reciprocal_ranks = []\n",
    "        for (u, v) in edges:\n",
    "            if (u not in model.kv) or (v not in model.kv):\n",
    "                continue\n",
    "            neighbors = u_to_all_neighbors[u]\n",
    "            neg_candidates = []\n",
    "            attempts = 0\n",
    "            while len(neg_candidates) < n_negatives and attempts < 10000:\n",
    "                candidate = rng.choice(vocab_list)\n",
    "                if candidate not in (u, v) and (candidate not in neighbors):\n",
    "                    neg_candidates.append(candidate)\n",
    "                attempts += 1\n",
    "            candidates = neg_candidates + [v]\n",
    "            dists = [(c, model.kv.distance(u, c)) for c in candidates]\n",
    "            sorted_nodes = [x[0] for x in sorted(dists, key=lambda x: x[1])]\n",
    "            try:\n",
    "                r = sorted_nodes.index(v) + 1\n",
    "                reciprocal_ranks.append(1.0 / r)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        return float(np.mean(reciprocal_ranks)) if reciprocal_ranks else 0.0\n",
    "\n",
    "    def link_prediction_mean_rank(model, edges, num_negatives=50):\n",
    "        rng = np.random.default_rng(1234)\n",
    "        ranks = []\n",
    "        for (source, target) in edges:\n",
    "            if (source not in model.kv) or (target not in model.kv):\n",
    "                continue\n",
    "            neg_candidates = []\n",
    "            attempts = 0\n",
    "            while len(neg_candidates) < num_negatives and attempts < 10000:\n",
    "                candidate = rng.choice(vocab_list)\n",
    "                if candidate != target and (source, candidate) not in all_edges_set:\n",
    "                    neg_candidates.append(candidate)\n",
    "                attempts += 1\n",
    "            if not neg_candidates:\n",
    "                continue\n",
    "            candidates = neg_candidates + [target]\n",
    "            dists = [model.kv.distance(source, c) for c in candidates]\n",
    "            sorted_candidates = [c for _, c in sorted(zip(dists, candidates), key=lambda x: x[0])]\n",
    "            rank = sorted_candidates.index(target) + 1\n",
    "            ranks.append(rank)\n",
    "        return float(np.mean(ranks)) if ranks else 0.0\n",
    "\n",
    "    def link_prediction_map(model, edges, num_negatives=50):\n",
    "        rng = np.random.default_rng(1234)\n",
    "        reciprocal_ranks = []\n",
    "        for (source, target) in edges:\n",
    "            if (source not in model.kv) or (target not in model.kv):\n",
    "                continue\n",
    "            neg_candidates = []\n",
    "            attempts = 0\n",
    "            while len(neg_candidates) < num_negatives and attempts < 10000:\n",
    "                candidate = rng.choice(vocab_list)\n",
    "                if candidate != target and (source, candidate) not in all_edges_set:\n",
    "                    neg_candidates.append(candidate)\n",
    "                attempts += 1\n",
    "            if not neg_candidates:\n",
    "                continue\n",
    "            candidates = neg_candidates + [target]\n",
    "            dists = [model.kv.distance(source, c) for c in candidates]\n",
    "            sorted_candidates = [c for _, c in sorted(zip(dists, candidates), key=lambda x: x[0])]\n",
    "            rank = sorted_candidates.index(target) + 1\n",
    "            reciprocal_ranks.append(1.0 / rank)\n",
    "        return float(np.mean(reciprocal_ranks)) if reciprocal_ranks else 0.0\n",
    "\n",
    "    def precision_at_k(model, edges, k=10, num_negatives=50):\n",
    "        rng = np.random.default_rng(1234)\n",
    "        hits = 0\n",
    "        count = 0\n",
    "        for (source, target) in edges:\n",
    "            if (source not in model.kv) or (target not in model.kv):\n",
    "                continue\n",
    "            neg_candidates = []\n",
    "            attempts = 0\n",
    "            while len(neg_candidates) < num_negatives and attempts < 10000:\n",
    "                candidate = rng.choice(vocab_list)\n",
    "                if candidate != target and (source, candidate) not in all_edges_set:\n",
    "                    neg_candidates.append(candidate)\n",
    "                attempts += 1\n",
    "            if not neg_candidates:\n",
    "                continue\n",
    "            candidates = neg_candidates + [target]\n",
    "            dists = [model.kv.distance(source, c) for c in candidates]\n",
    "            sorted_candidates = [c for _, c in sorted(zip(dists, candidates), key=lambda x: x[0])]\n",
    "            top_k_nodes = sorted_candidates[:k]\n",
    "            if target in top_k_nodes:\n",
    "                hits += 1\n",
    "            count += 1\n",
    "        return hits / count if count else 0.0\n",
    "\n",
    "    def recall_at_k(model, edges, k=10, num_negatives=50):\n",
    "        return precision_at_k(model, edges, k, num_negatives)\n",
    "\n",
    "\n",
    "    recon_mr_strict = reconstruction_mean_rank_strict_sampled(\n",
    "        model, train_relations, n_negatives=n_negatives_strict, seed=42\n",
    "    )\n",
    "    recon_map_strict = reconstruction_map_strict_sampled(\n",
    "        model, train_relations, n_negatives=n_negatives_strict, seed=42\n",
    "    )\n",
    "\n",
    "    lp_mr = link_prediction_mean_rank(model, test_relations, num_negatives=50)\n",
    "    lp_map_ = link_prediction_map(model, test_relations, num_negatives=50)\n",
    "    lp_p10 = precision_at_k(model, test_relations, k=10, num_negatives=50)\n",
    "    lp_r10 = recall_at_k(model, test_relations, k=10, num_negatives=50)\n",
    "\n",
    "    return {\n",
    "        \"reconstruction_mean_rank_strict\": recon_mr_strict,\n",
    "        \"reconstruction_map_strict\": recon_map_strict,\n",
    "        \"lp_mean_rank\": lp_mr,\n",
    "        \"lp_map\": lp_map_,\n",
    "        \"lp_precision_10\": lp_p10,\n",
    "        \"lp_recall_10\": lp_r10\n",
    "    }\n",
    "\n",
    "def run_multiple_experiments(\n",
    "    address,\n",
    "    dim_list,\n",
    "    removal_prob_list,\n",
    "    tsv_path,\n",
    "    subset_size=10000,\n",
    "    test_size=0.2,\n",
    "    epochs=300,\n",
    "    n_negatives_strict=500,\n",
    "    seed=42\n",
    "):\n",
    "    train_rel_clean, test_rel, combined_rel = prepare_custom_data(\n",
    "        tsv_path=tsv_path,\n",
    "        hypernym_col=\"Hypernym\",\n",
    "        hyponym_col=\"Hyponym\",\n",
    "        subset_size=subset_size,\n",
    "        test_size=test_size,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    all_results = []\n",
    "    for embedding_dim in dim_list:\n",
    "        for removal_prob in removal_prob_list:\n",
    "            print(\"========================================================\")\n",
    "            print(f\"RUNNING: dim={embedding_dim}, removal_prob={removal_prob:.2f}\")\n",
    "            print(\"========================================================\")\n",
    "\n",
    "           \n",
    "            modified_train = remove_edges(train_rel_clean, removal_probability=removal_prob, seed=seed)\n",
    "            removed_count = len(train_rel_clean) - len(modified_train)\n",
    "            print(f\"Removed {removed_count} edges from training set (prob={removal_prob}).\")\n",
    "\n",
    "            run_results = train_and_evaluate_poincare(\n",
    "                train_relations=modified_train,\n",
    "                test_relations=test_rel,\n",
    "                combined_relations=combined_rel,\n",
    "                embedding_dim=embedding_dim,\n",
    "                epochs=epochs,\n",
    "                n_negatives_strict=n_negatives_strict\n",
    "            )\n",
    "\n",
    "            row_info = {\n",
    "                \"embedding_dim\": embedding_dim,\n",
    "                \"edge_removal_probability\": removal_prob,\n",
    "                \"subset_size\": subset_size,\n",
    "                \"test_size\": test_size,\n",
    "                \"epochs\": epochs,\n",
    "                \"n_negatives_strict\": n_negatives_strict,\n",
    "            }\n",
    "            row_info.update(run_results)\n",
    "            all_results.append(row_info)\n",
    "\n",
    "    df = pd.DataFrame(all_results)\n",
    "    df.to_excel(address, index=False)\n",
    "    print(f\"\\nAll experiment results saved to: {address}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tsv_path = r\"Y:\\Data Science Readings\\Geometry of Information\\hebrew\\hebewnet.tsv\"\n",
    "    dimension_list = [5, 10,20,50,100,200]\n",
    "    removal_prob_list = [0.0, 0.1, 0.3] \n",
    "    excel_path = r\"Y:\\\\Data Science Readings\\\\Geometry of Information\\\\Milestone 3\\\\Milestone3-HebrewNet\\\\HebrewnetM3exp.xlsx\"\n",
    "\n",
    "    final_df = run_multiple_experiments(\n",
    "        address=excel_path,\n",
    "        dim_list=dimension_list,\n",
    "        removal_prob_list=removal_prob_list,\n",
    "        tsv_path=tsv_path,\n",
    "        subset_size=10000,\n",
    "        test_size=0.2,\n",
    "        epochs=100,\n",
    "        n_negatives_strict=50,\n",
    "        seed=42\n",
    "    )\n",
    "    print(\"\\nFinal DataFrame of all runs:\\n\")\n",
    "    print(final_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
