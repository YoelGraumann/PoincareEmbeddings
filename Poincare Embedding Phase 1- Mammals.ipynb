{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d0siFSzHMaMA"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import wordnet as wn\n",
    "from gensim.models.poincare import PoincareModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from gensim.models.poincare import PoincareModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from gensim.models.poincare import PoincareModel\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWqv4GANNokt",
    "outputId": "efb6fc7a-2f6e-48d6-94d4-9853bdb31b4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yoel1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mammals Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building transitive closure for the Mammal subtree...\n",
      "Total transitive hypernym pairs (mammal subtree): 7051\n",
      "Train relations: 5640\n",
      "Test relations : 1411\n",
      "========================================================\n",
      "RUNNING: dim=5, flip=0.00\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=5, flip=0.10\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=5, flip=0.30\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=10, flip=0.00\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=10, flip=0.10\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=10, flip=0.30\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=20, flip=0.00\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=20, flip=0.10\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=20, flip=0.30\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=50, flip=0.00\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=50, flip=0.10\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=50, flip=0.30\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=100, flip=0.00\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=100, flip=0.10\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=100, flip=0.30\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=200, flip=0.00\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=200, flip=0.10\n",
      "========================================================\n",
      "========================================================\n",
      "RUNNING: dim=200, flip=0.30\n",
      "========================================================\n",
      "\n",
      "All experiment results saved to: Y:\\Data Science Readings\\Geometry of Information\\MammalsExperiments\\mammal_exp.xlsx\n",
      "\n",
      "Final DataFrame of all runs:\n",
      "\n",
      "    embedding_dim  flip_probability  subset_size  test_size  epochs  \\\n",
      "0               5               0.0      1000000        0.2     100   \n",
      "1               5               0.1      1000000        0.2     100   \n",
      "2               5               0.3      1000000        0.2     100   \n",
      "3              10               0.0      1000000        0.2     100   \n",
      "4              10               0.1      1000000        0.2     100   \n",
      "5              10               0.3      1000000        0.2     100   \n",
      "6              20               0.0      1000000        0.2     100   \n",
      "7              20               0.1      1000000        0.2     100   \n",
      "8              20               0.3      1000000        0.2     100   \n",
      "9              50               0.0      1000000        0.2     100   \n",
      "10             50               0.1      1000000        0.2     100   \n",
      "11             50               0.3      1000000        0.2     100   \n",
      "12            100               0.0      1000000        0.2     100   \n",
      "13            100               0.1      1000000        0.2     100   \n",
      "14            100               0.3      1000000        0.2     100   \n",
      "15            200               0.0      1000000        0.2     100   \n",
      "16            200               0.1      1000000        0.2     100   \n",
      "17            200               0.3      1000000        0.2     100   \n",
      "\n",
      "    n_negatives_strict  reconstruction_mean_rank_strict  \\\n",
      "0                   10                         1.025709   \n",
      "1                   10                         1.121454   \n",
      "2                   10                         1.541667   \n",
      "3                   10                         1.025532   \n",
      "4                   10                         1.111879   \n",
      "5                   10                         1.524113   \n",
      "6                   10                         1.025532   \n",
      "7                   10                         1.114007   \n",
      "8                   10                         1.512234   \n",
      "9                   10                         1.024291   \n",
      "10                  10                         1.106560   \n",
      "11                  10                         1.505674   \n",
      "12                  10                         1.025177   \n",
      "13                  10                         1.110461   \n",
      "14                  10                         1.510284   \n",
      "15                  10                         1.023404   \n",
      "16                  10                         1.107624   \n",
      "17                  10                         1.495922   \n",
      "\n",
      "    reconstruction_map_strict  lp_mean_rank    lp_map  lp_precision_10  \\\n",
      "0                    0.987441      1.394326  0.880582         0.996454   \n",
      "1                    0.952722      1.829787  0.780377         0.985816   \n",
      "2                    0.830039      3.444681  0.529693         0.971631   \n",
      "3                    0.987722      1.368794  0.888714         0.995035   \n",
      "4                    0.956301      1.706383  0.803461         0.989362   \n",
      "5                    0.840319      3.239007  0.555654         0.971631   \n",
      "6                    0.987603      1.338298  0.896643         0.995745   \n",
      "7                    0.954982      1.721277  0.794434         0.990780   \n",
      "8                    0.843397      3.185816  0.559075         0.975177   \n",
      "9                    0.988283      1.338298  0.893399         0.995745   \n",
      "10                   0.957813      1.664539  0.808154         0.990780   \n",
      "11                   0.844263      3.173050  0.569964         0.971631   \n",
      "12                   0.987884      1.346099  0.893557         0.995035   \n",
      "13                   0.956511      1.658156  0.808608         0.990071   \n",
      "14                   0.843650      3.187234  0.571320         0.972340   \n",
      "15                   0.988549      1.356738  0.889676         0.995745   \n",
      "16                   0.957649      1.723404  0.799992         0.987234   \n",
      "17                   0.847183      3.168794  0.570429         0.973050   \n",
      "\n",
      "    lp_recall_10  \n",
      "0       0.996454  \n",
      "1       0.985816  \n",
      "2       0.971631  \n",
      "3       0.995035  \n",
      "4       0.989362  \n",
      "5       0.971631  \n",
      "6       0.995745  \n",
      "7       0.990780  \n",
      "8       0.975177  \n",
      "9       0.995745  \n",
      "10      0.990780  \n",
      "11      0.971631  \n",
      "12      0.995035  \n",
      "13      0.990071  \n",
      "14      0.972340  \n",
      "15      0.995745  \n",
      "16      0.987234  \n",
      "17      0.973050  \n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "def prepare_mammal_data(subset_size=10000, test_size=0.2, seed=42):\n",
    "    def extract_transitive_hypernyms_mammals():\n",
    "        mammal_synset = wn.synset('mammal.n.01')\n",
    "        mammal_synsets = set(mammal_synset.closure(lambda s: s.hyponyms()))\n",
    "        mammal_synsets.add(mammal_synset)\n",
    "\n",
    "        relations = []\n",
    "        for synset in mammal_synsets:\n",
    "            paths = synset.hypernym_paths()\n",
    "            for path in paths:\n",
    "                for ancestor in path:\n",
    "                    if ancestor in mammal_synsets and ancestor != synset:\n",
    "                        relations.append((synset.name(), ancestor.name()))\n",
    "        return relations\n",
    "\n",
    "    print(\"Building transitive closure for the Mammal subtree...\")\n",
    "    relations_list = extract_transitive_hypernyms_mammals()\n",
    "    print(f\"Total transitive hypernym pairs (mammal subtree): {len(relations_list)}\")\n",
    "\n",
    "    \n",
    "    if subset_size is not None and len(relations_list) > subset_size:\n",
    "        random.seed(seed)\n",
    "        relations_list = random.sample(relations_list, subset_size)\n",
    "        print(f\"Using a SUBSET of {subset_size} edges for faster testing.\")\n",
    "\n",
    "    \n",
    "    train_relations, test_relations = train_test_split(\n",
    "        relations_list, test_size=test_size, random_state=seed\n",
    "    )\n",
    "\n",
    "    print(f\"Train relations: {len(train_relations)}\")\n",
    "    print(f\"Test relations : {len(test_relations)}\")\n",
    "\n",
    "    combined_relations = train_relations + test_relations\n",
    "    return train_relations, test_relations, combined_relations\n",
    "\n",
    "\n",
    "\n",
    "def flip_edge_directions(relations, flip_probability=0.1, seed=42):\n",
    "    random.seed(seed)\n",
    "    flipped_relations = []\n",
    "    for (child, ancestor) in relations:\n",
    "        if random.random() < flip_probability:\n",
    "            flipped_relations.append((ancestor, child))  \n",
    "        else:\n",
    "            flipped_relations.append((child, ancestor))  \n",
    "    return flipped_relations\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate_poincare(\n",
    "    train_relations,\n",
    "    test_relations,\n",
    "    combined_relations,\n",
    "    embedding_dim=5,\n",
    "    epochs=300,\n",
    "    n_negatives_strict=500,\n",
    "):\n",
    "\n",
    "   \n",
    "    model = PoincareModel(\n",
    "        train_data=train_relations,\n",
    "        size=embedding_dim,\n",
    "        negative=10,  \n",
    "        burn_in=10    \n",
    "    )\n",
    "    model.train(epochs=epochs)\n",
    "\n",
    "    \n",
    "    u_to_all_neighbors = defaultdict(set)\n",
    "    for (child, ancestor) in combined_relations:\n",
    "        u_to_all_neighbors[child].add(ancestor)\n",
    "\n",
    "    vocab_nodes = set(model.kv.index_to_key)\n",
    "    vocab_list = list(vocab_nodes)\n",
    "    all_edges_set = set(combined_relations)\n",
    "\n",
    "    def reconstruction_mean_rank_strict_sampled(model, edges, n_negatives=500, seed=1234):\n",
    "        rng = np.random.default_rng(seed)\n",
    "        ranks = []\n",
    "        for (u, v) in edges:\n",
    "            if (u not in model.kv) or (v not in model.kv):\n",
    "                continue\n",
    "            neighbors = u_to_all_neighbors[u]\n",
    "            neg_candidates = []\n",
    "            attempts = 0\n",
    "            while len(neg_candidates) < n_negatives and attempts < 10000:\n",
    "                candidate = rng.choice(vocab_list)\n",
    "                if candidate not in (u, v) and (candidate not in neighbors):\n",
    "                    neg_candidates.append(candidate)\n",
    "                attempts += 1\n",
    "            candidates = neg_candidates + [v]\n",
    "            dists = [(c, model.kv.distance(u, c)) for c in candidates]\n",
    "            sorted_nodes = [x[0] for x in sorted(dists, key=lambda x: x[1])]\n",
    "            try:\n",
    "                rank = sorted_nodes.index(v) + 1\n",
    "                ranks.append(rank)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        return float(np.mean(ranks)) if ranks else 0.0\n",
    "\n",
    "    def reconstruction_map_strict_sampled(model, edges, n_negatives=500, seed=1234):\n",
    "        rng = np.random.default_rng(seed)\n",
    "        reciprocal_ranks = []\n",
    "        for (u, v) in edges:\n",
    "            if (u not in model.kv) or (v not in model.kv):\n",
    "                continue\n",
    "            neighbors = u_to_all_neighbors[u]\n",
    "            neg_candidates = []\n",
    "            attempts = 0\n",
    "            while len(neg_candidates) < n_negatives and attempts < 10000:\n",
    "                candidate = rng.choice(vocab_list)\n",
    "                if candidate not in (u, v) and (candidate not in neighbors):\n",
    "                    neg_candidates.append(candidate)\n",
    "                attempts += 1\n",
    "            candidates = neg_candidates + [v]\n",
    "            dists = [(c, model.kv.distance(u, c)) for c in candidates]\n",
    "            sorted_nodes = [x[0] for x in sorted(dists, key=lambda x: x[1])]\n",
    "            try:\n",
    "                r = sorted_nodes.index(v) + 1\n",
    "                reciprocal_ranks.append(1.0 / r)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        return float(np.mean(reciprocal_ranks)) if reciprocal_ranks else 0.0\n",
    "\n",
    "    def link_prediction_mean_rank(model, edges, num_negatives=50):\n",
    "        rng = np.random.default_rng(1234)\n",
    "        ranks = []\n",
    "        for (source, target) in edges:\n",
    "            if source not in vocab_nodes or target not in vocab_nodes:\n",
    "                continue\n",
    "            neg_candidates = []\n",
    "            attempts = 0\n",
    "            while len(neg_candidates) < num_negatives and attempts < 10000:\n",
    "                candidate = rng.choice(vocab_list)\n",
    "                \n",
    "                if candidate != target and (source, candidate) not in all_edges_set:\n",
    "                    neg_candidates.append(candidate)\n",
    "                attempts += 1\n",
    "            if not neg_candidates:\n",
    "                continue\n",
    "            candidates = neg_candidates + [target]\n",
    "            dists = [model.kv.distance(source, c) for c in candidates]\n",
    "            sorted_candidates = [c for _, c in sorted(zip(dists, candidates), key=lambda x: x[0])]\n",
    "            rank = sorted_candidates.index(target) + 1\n",
    "            ranks.append(rank)\n",
    "        return float(np.mean(ranks)) if ranks else 0.0\n",
    "\n",
    "    def link_prediction_map(model, edges, num_negatives=50):\n",
    "        rng = np.random.default_rng(1234)\n",
    "        reciprocal_ranks = []\n",
    "        for (source, target) in edges:\n",
    "            if source not in vocab_nodes or target not in vocab_nodes:\n",
    "                continue\n",
    "            neg_candidates = []\n",
    "            attempts = 0\n",
    "            while len(neg_candidates) < num_negatives and attempts < 10000:\n",
    "                candidate = rng.choice(vocab_list)\n",
    "                if candidate != target and (source, candidate) not in all_edges_set:\n",
    "                    neg_candidates.append(candidate)\n",
    "                attempts += 1\n",
    "            if not neg_candidates:\n",
    "                continue\n",
    "            candidates = neg_candidates + [target]\n",
    "            dists = [model.kv.distance(source, c) for c in candidates]\n",
    "            sorted_candidates = [c for _, c in sorted(zip(dists, candidates), key=lambda x: x[0])]\n",
    "            rank = sorted_candidates.index(target) + 1\n",
    "            reciprocal_ranks.append(1.0 / rank)\n",
    "        return float(np.mean(reciprocal_ranks)) if reciprocal_ranks else 0.0\n",
    "\n",
    "    def precision_at_k(model, edges, k=10, num_negatives=50):\n",
    "        rng = np.random.default_rng(1234)\n",
    "        hits = 0\n",
    "        count = 0\n",
    "        for (source, target) in edges:\n",
    "            if source not in vocab_nodes or target not in vocab_nodes:\n",
    "                continue\n",
    "            neg_candidates = []\n",
    "            attempts = 0\n",
    "            while len(neg_candidates) < num_negatives and attempts < 10000:\n",
    "                candidate = rng.choice(vocab_list)\n",
    "                if candidate != target and (source, candidate) not in all_edges_set:\n",
    "                    neg_candidates.append(candidate)\n",
    "                attempts += 1\n",
    "            if not neg_candidates:\n",
    "                continue\n",
    "            candidates = neg_candidates + [target]\n",
    "            dists = [model.kv.distance(source, c) for c in candidates]\n",
    "            sorted_candidates = [c for _, c in sorted(zip(dists, candidates), key=lambda x: x[0])]\n",
    "            top_k_nodes = sorted_candidates[:k]\n",
    "            if target in top_k_nodes:\n",
    "                hits += 1\n",
    "            count += 1\n",
    "        return hits / count if count else 0.0\n",
    "\n",
    "    def recall_at_k(model, edges, k=10, num_negatives=50):\n",
    "        \n",
    "        return precision_at_k(model, edges, k, num_negatives)\n",
    "\n",
    "    \n",
    "    recon_mr_strict = reconstruction_mean_rank_strict_sampled(\n",
    "        model, train_relations, n_negatives=n_negatives_strict, seed=42\n",
    "    )\n",
    "    recon_map_strict = reconstruction_map_strict_sampled(\n",
    "        model, train_relations, n_negatives=n_negatives_strict, seed=42\n",
    "    )\n",
    "\n",
    "    \n",
    "    lp_mr = link_prediction_mean_rank(model, test_relations, num_negatives=50)\n",
    "    lp_map_ = link_prediction_map(model, test_relations, num_negatives=50)\n",
    "    lp_p10 = precision_at_k(model, test_relations, k=10, num_negatives=50)\n",
    "    lp_r10 = recall_at_k(model, test_relations, k=10, num_negatives=50)\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"reconstruction_mean_rank_strict\": recon_mr_strict,\n",
    "        \"reconstruction_map_strict\": recon_map_strict,\n",
    "        \"lp_mean_rank\": lp_mr,\n",
    "        \"lp_map\": lp_map_,\n",
    "        \"lp_precision_10\": lp_p10,\n",
    "        \"lp_recall_10\": lp_r10,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def run_multiple_experiments(\n",
    "    address,                \n",
    "    dim_list,               \n",
    "    flip_list,              \n",
    "    subset_size=10000,\n",
    "    test_size=0.2,\n",
    "    epochs=300,\n",
    "    n_negatives_strict=500,\n",
    "    seed=42\n",
    "):\n",
    "    \n",
    "    train_relations_clean, test_relations, combined_relations = prepare_mammal_data(\n",
    "        subset_size=subset_size,\n",
    "        test_size=test_size,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    \n",
    "    all_results = []\n",
    "\n",
    "    for embedding_dim in dim_list:\n",
    "        for flip_probability in flip_list:\n",
    "            print(\"========================================================\")\n",
    "            print(f\"RUNNING: dim={embedding_dim}, flip={flip_probability:.2f}\")\n",
    "            print(\"========================================================\")\n",
    "\n",
    "            \n",
    "            flipped_train = flip_edge_directions(\n",
    "                train_relations_clean,\n",
    "                flip_probability=flip_probability,\n",
    "                seed=seed\n",
    "            )\n",
    "\n",
    "            \n",
    "            run_results = train_and_evaluate_poincare(\n",
    "                train_relations=flipped_train,\n",
    "                test_relations=test_relations,\n",
    "                combined_relations=combined_relations,\n",
    "                embedding_dim=embedding_dim,\n",
    "                epochs=epochs,\n",
    "                n_negatives_strict=n_negatives_strict\n",
    "            )\n",
    "\n",
    "            \n",
    "            row_info = {\n",
    "                \"embedding_dim\": embedding_dim,\n",
    "                \"flip_probability\": flip_probability,\n",
    "                \"subset_size\": subset_size,\n",
    "                \"test_size\": test_size,\n",
    "                \"epochs\": epochs,\n",
    "                \"n_negatives_strict\": n_negatives_strict,\n",
    "            }\n",
    "            row_info.update(run_results)  \n",
    "            all_results.append(row_info)\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(all_results)\n",
    "\n",
    "    \n",
    "    df.to_excel(address, index=False)\n",
    "    print(f\"\\nAll experiment results saved to: {address}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dimension_list = [5, 10,20,50,100,200]          \n",
    "    flip_probability_list = [0.0, 0.1, 0.3]  \n",
    "    excel_path = \"Y:\\\\Data Science Readings\\\\Geometry of Information\\\\MammalsExperiments\\\\mammal_exp.xlsx\"\n",
    "    final_df = run_multiple_experiments(\n",
    "        address=excel_path,\n",
    "        dim_list=dimension_list,\n",
    "        flip_list=flip_probability_list,\n",
    "        subset_size=1000000,        \n",
    "        test_size=0.2,\n",
    "        epochs=100,               \n",
    "        n_negatives_strict=10,\n",
    "        seed=42\n",
    "    )\n",
    "    print(\"\\nFinal DataFrame of all runs:\\n\")\n",
    "    print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
